{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Gradient Descent of a vector-valued function.\n",
    "$$\n",
    "f(x)=x^T \\begin{bmatrix} 3 & 2 \\\\ 2 & 3 \\end{bmatrix} x + x^T \\begin{bmatrix} 3 \\\\ -1 \\end{bmatrix} -22\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[3,2],[2,3]])\n",
    "b = np.array([3,-1])\n",
    "x0 = np.array([0,0])\n",
    "\n",
    "f = lambda x : x @ Q @ x + b @ x - 22\n",
    "\n",
    "convergenceLimit = 1e-5\n",
    "iterationLimit = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = lambda x : 2 * Q @ x + b\n",
    "step = lambda grad : (grad @ grad) / (grad @ (2 * Q) @ grad)\n",
    "convergenceRate = lambda f, xn, x0 : (abs(f(xn)-f(x0)))/(max(1, abs(f(x0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\tx: [-0.83333333  0.27777778]\tf(x): -23.38888888888889\tconvRate: 0.06313131313131315\n",
      "iteration 2\tx: [-0.72751323  0.5952381 ]\tf(x): -23.85920047031158\tconvRate: 0.02010833364752602\n",
      "iteration 3\tx: [-1.00970018  0.68930041]\tf(x): -24.01845941851821\tconvRate: 0.006674949079068933\n",
      "iteration 4\tx: [-0.97386691  0.7968002 ]\tf(x): -24.072388374524685\tconvRate: 0.0022453128681891\n",
      "iteration 5\tx: [-1.06942228  0.82865199]\tf(x): -24.090650031585078\tconvRate: 0.0007586142586382728\n",
      "iteration 6\tx: [-1.05728827  0.86505404]\tf(x): -24.096833873129338\tconvRate: 0.0002566905225119503\n",
      "iteration 7\tx: [-1.08964564  0.87583983]\tf(x): -24.098927872382422\tconvRate: 8.689935217668661e-05\n",
      "iteration 8\tx: [-1.08553677  0.88816645]\tf(x): -24.099636951494578\tconvRate: 2.942367875909429e-05\n",
      "iteration 9\tx: [-1.09649376  0.89181878]\tf(x): -24.099877062939964\tconvRate: 9.963280603327005e-06\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "while(True):\n",
    "    grad = gradient(x0)\n",
    "    xn = x0 - (step(grad) * grad)\n",
    "    convRate = convergenceRate(f, xn, x0)\n",
    "\n",
    "    iteration += 1\n",
    "    print(\"iteration \"+str(iteration)+\"\\tx: \"+str(xn)+\"\\tf(x): \"+str(f(xn))+\"\\tconvRate: \"+str(convRate))\n",
    "    \n",
    "    x0 = xn\n",
    "\n",
    "    if iteration == iterationLimit or convRate < convergenceLimit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result f(x): -24.099877062939964\n"
     ]
    }
   ],
   "source": [
    "result = f(x0)\n",
    "print(\"Result f(x): \"+str(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
